{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASGN Standardization \n",
    "\n",
    "- Seperate out continuous and non-continuous variables for the assignment and this will then be the ones, drop off those variables you don't want, to include in your array. \n",
    "\n",
    "- r2 should be very low. \n",
    "\n",
    "## The Cardinal sin of data leakage\n",
    "\n",
    "**Having data in the training sample that you wouldn't have for real world predictions**\n",
    "\n",
    "Examples\n",
    "1. y is explicitly in X (yikes)\n",
    "2. y is a 2018 variable, but there is a 2019 variable in X\n",
    "3. subtle: y is loan default, but X contains employee ID and some employees are brought in to handle trouble-loans (if you include it, the firm can't use the model to deploy the trouble-loan specialists)\n",
    "4. if out-of-sample predicted stock movements have R2 above 10%... unlikely! (or: you'll be richer than Bezos soon)\n",
    "5. this code belowâ€©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Data Leakage\n",
    "\n",
    "- Preventing 1-4: Be very familiar with the data and how it was collected and built \n",
    "- Preventing 5: Do your data prep _**within**_ CV folds and where the transformations are done using only info from the training \n",
    "\n",
    "```python\n",
    "\n",
    "# loop over folds \n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,y):\n",
    "\n",
    "    # .split() yields the indices in train/test sets. use those to get \n",
    "    # the x/y vars for each separated out:\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "###################################################################\n",
    "    # NEW: do the data prep inside this fold, only using training data \n",
    "    ###################################################################\n",
    "\n",
    "    # e.g. figure out means/std in Xtrain so we can impute/std\n",
    "    prep_methods.fit(Xtrain)                 # \"fit\" the transform means \"estimate (like in training a model) what to do\"\n",
    "    Xtrain = prep_methods.transform(Xtrain)  # apply those to Xtrain to impute and std\n",
    "    \n",
    "    # fit/estimate, predict OOS, evaluate and store\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    ###################################################################\n",
    "    # NEW: transform the test data the same... \n",
    "    ###################################################################\n",
    "    \n",
    "    X_test = prep_methods.transform(X_test)  # apply TEST data the FIT from the TRAIN data \n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "    accuracy.append(   accuracy_score(y_test, y_predict)      )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00743794, 0.00287795, 0.00203085, 0.00188613, 0.00221181]),\n",
       " 'score_time': array([0.002666  , 0.00086117, 0.00051022, 0.00148416, 0.00118399]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.96666667, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "\n",
    "iris = load_iris() # data\n",
    "\n",
    "# set up the pipeline, which will, given a set of observations \n",
    "# 1. fit and apply these steps to the training fold\n",
    "# 2. in the testing fold, apply the transform and model to predict (no estimation)\n",
    "\n",
    "classifier_pipeline = make_pipeline(\n",
    "                                    preprocessing.StandardScaler(),  # clean the data\n",
    "                                    svm.SVC(C=1)                     # model\n",
    "                                    )\n",
    "\n",
    "cross_validate(classifier_pipeline, iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1: try this with a Nearest Neighbors Classifier (5 min)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_pipe = make_pipeline(\n",
    "                        preprocessing.StandardScaler(),  # clean the data\n",
    "                        KNeighborsClassifier()           # model\n",
    "                        )\n",
    "\n",
    "cross_validate(classifier_pipeline, iris.data, iris.target, cv=5)\n",
    "\n",
    "iris2 = load_iris()\n",
    "X2 = pd.DataFrame(iris2.data)\n",
    "X2.columns = [1,2,3,4]\n",
    "X2[2] = X2[2].sample(frac=0.5,random_state=14)\n",
    "X2[2].describe()\n",
    "iris2.data = X2\n",
    "\n",
    "# print the scores using IRIS2.data (not iris.data)\n",
    "# this produces an error because of the missing values!\n",
    "# cross_validate(knn_pipe, iris2.data, iris.target, cv=5)\n",
    "\n",
    "# so add an imputation step to the pipeline! (5 min, use lecture page!)\n",
    "knn_pipe2 = ......\n",
    "cross_validate(knn_pipe2, iris2.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so add an imputation step to the pipeline! (5 min, use lecture page!)\n",
    "from sklearn.impute import SimpleImputer\n",
    "knn_pipe2 = make_pipeline(\n",
    "                        SimpleImputer(strategy='mean'),  # fill missing values\n",
    "                        preprocessing.StandardScaler(),  # clean the data\n",
    "                        KNeighborsClassifier()           # model\n",
    "                        )\n",
    "\n",
    "cross_validate(knn_pipe2, iris2.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search will let you specify all the parameters of the model\n",
    "# you want to tweak, and the values you want to try\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up parameter grid to try\n",
    "# the parameter grid is a dictionary where key:value pairs are built like:\n",
    "#     stepName<two underlines>paramName : [list of settings to try]\n",
    "param_grid = {'kneighborsclassifier__n_neighbors':[1,5,6,7,8,9,10]}\n",
    "\n",
    "# like a normal estimator, this has not yet been applied to any data\n",
    "grid = GridSearchCV(knn_pipe2, param_grid=param_grid)\n",
    "grid.fit(iris2.data, iris.target)\n",
    "grid.best_params_\n",
    "\n",
    "# now save that pipeline as a model object!\n",
    "optimal_knn_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final Summary\n",
    "\n",
    "- We've now seen more post model diagnostics \n",
    "- We can specify the models in `make_pipeline` alongside data cleaning/preprocessing steps that improve model performance without introducing data leakage. \n",
    "- There are many imputation, and scaling methods available in `sklearn`, and which one you use depends on the use-case. (Read about and try several!)\n",
    "- Your pipeline for the assignment will be more complicated if you want to include categorical vars\n",
    "- You can optimize all of the parameters throughout your pipeline using `GridSearchCV`\n",
    "    - `GridSearchCV` also allows you to specify how you create folds\n",
    "    - Which leads us to...\n",
    "\n",
    "**LAST BIG POINT:** \n",
    "- Must of your projects involve an important time series dimension. (Ex: predicting stock returns) \n",
    "- In these cases, `KFold` and `StratifiedKFold` won't work (you can't have 1985 in the test sample)\n",
    "- See: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
