{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What you should learn/be aware of based on this lecture? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key sklearn functions:\n",
    "- train_test_split\n",
    "- cross_validate\n",
    "- Fold generators: KFold and StratifiedKFold\n",
    "- Scoring functions per last lecture and how to pass to cross_validate\n",
    "- How to compare different models by looping over them with cross_validate, GridSearchCV, or RandomizedSearchCV\n",
    "- Not covered today but you should check out:\n",
    "    confusion_matrix and classification_report (helpful to evaluate models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "\n",
    "- Break the X and y data into $k$ subsamples\n",
    "- For each subsample, fit the model, predict OOS, score predictions, and save those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
